#!/usr/bin/env python3
"""
PostgreSQL Migration Script (Part 1) - Database Setup

This script:
1. Creates the necessary PostgreSQL schema for the AMR Predictor API
2. Sets up environment variables and configuration for different environments
3. Creates a migration plan for the data transfer

Prerequisites:
- PostgreSQL installed and running
- psycopg2 package installed (pip install psycopg2-binary)
- python-dotenv for environment management

Usage:
    python migrate_to_postgresql_part1.py
"""
import os
import sys
import sqlite3
import psycopg2
from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT
from psycopg2 import pool
from pathlib import Path
from dotenv import load_dotenv
import argparse
import logging

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger("pg-migration")

# Get project root directory
PROJECT_ROOT = Path(__file__).parent.resolve()
SQLITE_DB_PATH = PROJECT_ROOT / "amr_predictor" / "core" / "amr_predictor.db"
ENV_FILE_PATH = PROJECT_ROOT / ".env"

def create_dotenv_file(pg_host, pg_port, pg_user, pg_password):
    """Create or update the .env file with PostgreSQL credentials"""
    # Create default .env file if it doesn't exist
    if not ENV_FILE_PATH.exists():
        logger.info(f"Creating new .env file at {ENV_FILE_PATH}")
        
        # Build env file content
        env_content = f"""# PostgreSQL Database Configuration
# Generated by migration script

# Connection details
PG_HOST={pg_host}
PG_PORT={pg_port}
PG_USER={pg_user}
PG_PASSWORD={pg_password}

# Database names for different environments
PG_DATABASE_DEV=amr_predictor_dev
PG_DATABASE_TEST=amr_predictor_test
PG_DATABASE_PROD=amr_predictor_prod

# Current environment (dev, test, or prod)
ENVIRONMENT=dev

# Other settings
HF_TOKEN=  # Optional: Add your Hugging Face token if needed
"""
        with open(ENV_FILE_PATH, 'w') as f:
            f.write(env_content)
        logger.info(f".env file created successfully")
    else:
        # Update existing .env file
        logger.info(f"Updating existing .env file at {ENV_FILE_PATH}")
        
        # Load existing environment variables
        load_dotenv(ENV_FILE_PATH)
        
        # Read current content
        with open(ENV_FILE_PATH, 'r') as f:
            env_content = f.read()
        
        # Check if PostgreSQL configs already exist
        pg_configs = [
            'PG_HOST', 'PG_PORT', 'PG_USER', 'PG_PASSWORD', 
            'PG_DATABASE_DEV', 'PG_DATABASE_TEST', 'PG_DATABASE_PROD',
            'ENVIRONMENT'
        ]
        
        # If any PostgreSQL configs are missing, add them
        missing_configs = []
        for config in pg_configs:
            if config not in env_content:
                missing_configs.append(config)
        
        if missing_configs:
            logger.info(f"Adding missing PostgreSQL configs to .env file: {', '.join(missing_configs)}")
            
            with open(ENV_FILE_PATH, 'a') as f:
                f.write("\n# PostgreSQL Database Configuration (added by migration script)\n")
                
                if 'PG_HOST' in missing_configs:
                    f.write(f"PG_HOST={pg_host}\n")
                if 'PG_PORT' in missing_configs:
                    f.write(f"PG_PORT={pg_port}\n")
                if 'PG_USER' in missing_configs:
                    f.write(f"PG_USER={pg_user}\n")
                if 'PG_PASSWORD' in missing_configs:
                    f.write(f"PG_PASSWORD={pg_password}\n")
                if 'PG_DATABASE_DEV' in missing_configs:
                    f.write("PG_DATABASE_DEV=amr_predictor_dev\n")
                if 'PG_DATABASE_TEST' in missing_configs:
                    f.write("PG_DATABASE_TEST=amr_predictor_test\n")
                if 'PG_DATABASE_PROD' in missing_configs:
                    f.write("PG_DATABASE_PROD=amr_predictor_prod\n")
                if 'ENVIRONMENT' in missing_configs:
                    f.write("ENVIRONMENT=dev\n")
        else:
            logger.info("All required PostgreSQL configurations already exist in .env file")

def create_postgresql_databases():
    """Create PostgreSQL databases for dev, test, and prod environments"""
    # Load environment variables
    load_dotenv(ENV_FILE_PATH)
    
    # Get connection parameters from environment
    pg_host = os.getenv('PG_HOST', 'localhost')
    pg_port = os.getenv('PG_PORT', '5432')
    pg_user = os.getenv('PG_USER', 'postgres')
    pg_password = os.getenv('PG_PASSWORD', '')
    
    # List of databases to create
    database_envs = {
        'dev': os.getenv('PG_DATABASE_DEV', 'amr_predictor_dev'),
        'test': os.getenv('PG_DATABASE_TEST', 'amr_predictor_test'),
        'prod': os.getenv('PG_DATABASE_PROD', 'amr_predictor_prod')
    }
    
    # Connect to PostgreSQL server
    try:
        # Connect to default database to create our custom databases
        conn = psycopg2.connect(
            host=pg_host,
            port=pg_port,
            user=pg_user,
            password=pg_password,
            database="postgres"
        )
        conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)
        cursor = conn.cursor()
        
        # Check and create each database
        for env, db_name in database_envs.items():
            # Check if database exists
            cursor.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
            exists = cursor.fetchone()
            
            if not exists:
                logger.info(f"Creating '{env}' database: {db_name}")
                cursor.execute(f"CREATE DATABASE {db_name}")
                logger.info(f"Database '{db_name}' created successfully")
            else:
                logger.info(f"Database '{db_name}' already exists")
        
        cursor.close()
        conn.close()
        
        return True
    except Exception as e:
        logger.error(f"Error creating PostgreSQL databases: {str(e)}")
        return False

def create_postgresql_schema(env='dev'):
    """Create the required schema in the PostgreSQL database"""
    # Load environment variables
    load_dotenv(ENV_FILE_PATH)
    
    # Get connection parameters
    pg_host = os.getenv('PG_HOST', 'localhost')
    pg_port = os.getenv('PG_PORT', '5432')
    pg_user = os.getenv('PG_USER', 'postgres')
    pg_password = os.getenv('PG_PASSWORD', '')
    
    # Get the appropriate database based on environment
    if env == 'dev':
        database = os.getenv('PG_DATABASE_DEV', 'amr_predictor_dev')
    elif env == 'test':
        database = os.getenv('PG_DATABASE_TEST', 'amr_predictor_test')
    elif env == 'prod':
        database = os.getenv('PG_DATABASE_PROD', 'amr_predictor_prod')
    else:
        logger.error(f"Invalid environment: {env}")
        return False
    
    logger.info(f"Setting up schema for '{env}' environment in database '{database}'")
    
    # Connect to the specified database
    try:
        conn = psycopg2.connect(
            host=pg_host,
            port=pg_port,
            user=pg_user,
            password=pg_password,
            database=database
        )
        cursor = conn.cursor()
        
        # Create users table (if needed by your application)
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS users (
            id SERIAL PRIMARY KEY,
            username VARCHAR(255) UNIQUE NOT NULL,
            email VARCHAR(255) UNIQUE NOT NULL,
            password_hash VARCHAR(255) NOT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            last_login TIMESTAMP
        )
        """)
        
        # Create amr_jobs table
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS amr_jobs (
            id VARCHAR(255) PRIMARY KEY,
            status VARCHAR(50) NOT NULL,
            progress FLOAT DEFAULT 0,
            start_time TIMESTAMP,
            end_time TIMESTAMP,
            result_file VARCHAR(255),
            aggregated_result_file VARCHAR(255),
            error TEXT,
            additional_info JSONB
        )
        """)
        
        # Create amr_job_parameters table
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS amr_job_parameters (
            id SERIAL PRIMARY KEY,
            job_id VARCHAR(255) REFERENCES amr_jobs(id) ON DELETE CASCADE,
            param_name VARCHAR(255) NOT NULL,
            param_value TEXT,
            UNIQUE(job_id, param_name)
        )
        """)
        
        # Create indexes for better performance
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_job_status ON amr_jobs(status)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_job_parameters ON amr_job_parameters(job_id)")
        
        # Commit changes
        conn.commit()
        cursor.close()
        conn.close()
        
        logger.info(f"PostgreSQL schema created successfully for '{env}' environment")
        return True
    except Exception as e:
        logger.error(f"Error creating PostgreSQL schema: {str(e)}")
        return False

def check_sqlite_database():
    """Check if SQLite database exists and count the data to migrate"""
    if not SQLITE_DB_PATH.exists():
        logger.warning(f"SQLite database not found at {SQLITE_DB_PATH}")
        return False
    
    try:
        # Connect to SQLite database
        sqlite_conn = sqlite3.connect(SQLITE_DB_PATH)
        sqlite_cursor = sqlite_conn.cursor()
        
        # Check if the required tables exist
        sqlite_cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='amr_jobs'")
        if not sqlite_cursor.fetchone():
            logger.warning("amr_jobs table not found in SQLite database")
            sqlite_conn.close()
            return False
        
        # Count the number of jobs to migrate
        sqlite_cursor.execute("SELECT COUNT(*) FROM amr_jobs")
        job_count = sqlite_cursor.fetchone()[0]
        
        # Count job parameters
        sqlite_cursor.execute("SELECT COUNT(*) FROM amr_job_parameters")
        param_count = sqlite_cursor.fetchone()[0]
        
        logger.info(f"Found {job_count} jobs and {param_count} job parameters to migrate")
        
        sqlite_conn.close()
        return True
    except Exception as e:
        logger.error(f"Error checking SQLite database: {str(e)}")
        return False

def main():
    # Parse command-line arguments
    parser = argparse.ArgumentParser(description="PostgreSQL Migration Script - Part 1")
    parser.add_argument("--host", default="localhost", help="PostgreSQL host")
    parser.add_argument("--port", default="5432", help="PostgreSQL port")
    parser.add_argument("--user", default="postgres", help="PostgreSQL user")
    parser.add_argument("--password", default="", help="PostgreSQL password")
    parser.add_argument("--env", default="dev", choices=["dev", "test", "prod"], 
                        help="Environment to set up")
    args = parser.parse_args()
    
    logger.info("Starting PostgreSQL migration - Part 1 (Database Setup)")
    
    # Step 1: Create/update .env file with PostgreSQL credentials
    logger.info("Step 1: Setting up environment variables")
    create_dotenv_file(args.host, args.port, args.user, args.password)
    
    # Step 2: Create PostgreSQL databases for all environments
    logger.info("Step 2: Creating PostgreSQL databases")
    if not create_postgresql_databases():
        logger.error("Failed to create PostgreSQL databases. Exiting.")
        return 1
    
    # Step 3: Create schema in the specified environment
    logger.info(f"Step 3: Creating PostgreSQL schema for {args.env} environment")
    if not create_postgresql_schema(args.env):
        logger.error(f"Failed to create schema for {args.env} environment. Exiting.")
        return 1
    
    # Step 4: Check SQLite database for migration
    logger.info("Step 4: Checking SQLite database")
    if check_sqlite_database():
        logger.info("SQLite database found with data to migrate")
        logger.info("Please run migrate_to_postgresql_part2.py to migrate the data")
    else:
        logger.info("No SQLite data to migrate, schema setup is complete")
        logger.info("Please run migrate_to_postgresql_part3.py to update the database manager")
    
    logger.info("Database setup completed successfully!")
    return 0

if __name__ == "__main__":
    sys.exit(main())
